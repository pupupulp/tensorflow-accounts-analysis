{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Machine Learning\n",
    "\n",
    "In this notebook, we will explore ways to analyze data, build models, and apply predictions on data corresponding to financial accounts. The idea is to grasp how machine learning works and evaluate its uses on financial systems.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing required libraries \n",
    "\n",
    "Here are the list of essential libraries used for building machine learning models and implementing predictions.\n",
    "\n",
    "### Tensorflow\n",
    "    An open source software library used for conducting machine learning and deep neural networks research.\n",
    "\n",
    "### Numpy\n",
    "    An open source package for python used for scientific computing that supports large, multidimensional arrays and matrices, and is mainly used for data analysis.\n",
    "\n",
    "### Pandas\n",
    "    An open source library aimed to be the fundamental high-level building block for doing practical, real world data analysis in Python, and is mainly used for data manipulation and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow v1.10.1\n",
      "Numpy v1.14.5\n",
      "Pandas v0.23.4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "print(\"TensorFlow v\" + tf.__version__)\n",
    "print(\"Numpy v\" + np.__version__)\n",
    "print(\"Pandas v\" + pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of sample data\n",
    "\n",
    "There is already an existing database in which dataset can be queried from, but on this experiment we will be using an already exported CSV file of the dataset. For inquiries on how will the flow be when getting dataset by utilizing BigQuery, below is a sample flow :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import google.datalab.bigquery as bq\n",
    "    \n",
    "# raw_query = \"\"\"\n",
    "#     select something from data source where something = PARAMS\n",
    "# \"\"\"\n",
    "\n",
    "# query = raw_query.replace(\"PARAMS\", \"params_value\")\n",
    "\n",
    "# result_set = bq.Query(query).execute().result().to_dataframe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
